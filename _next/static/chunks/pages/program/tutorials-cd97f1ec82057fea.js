(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[867],{9160:function(e,a,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/program/tutorials",function(){return s(4522)}])},4779:function(e,a,s){"use strict";s.d(a,{Z:function(){return d}});var t=s(5893),i=s(1163),n=s(5675),r=s.n(n),l=s(9229);let o=()=>(0,t.jsxs)("header",{children:[(0,t.jsxs)("div",{className:"max-w-[70em] h-[4em] mx-auto flex justify-between pr-3.5",children:[(0,t.jsxs)("div",{className:"bg-gray-900 px-5 py-1 flex flex-col items-center justify-center",children:[(0,t.jsxs)("h1",{className:"text-3xl font-bold block",children:[(0,t.jsx)("span",{className:"text-gray-200",children:"A"}),(0,t.jsx)("span",{className:"text-gray-300",children:"D"}),(0,t.jsx)("span",{className:"text-gray-400",children:"C"}),(0,t.jsx)("span",{className:"text-orange-600",children:"2023"})]}),(0,t.jsx)("p",{className:"text-gray-500 font-semibold block text-xs mt-[-0.2em]",children:"Melbourne, AU"})]}),(0,t.jsx)("div",{className:"flex",children:(0,t.jsx)(l.w,{})})]}),(0,t.jsx)("div",{className:"h-[500px] w-full absolute top-[4em]",children:(0,t.jsx)(r(),{className:"w-full h-full object-cover",src:"/images/melb.jpg",alt:"",width:2400,height:1798,priority:!0})})]}),c=e=>{let{children:a}=e,s=(0,i.useRouter)();return(0,t.jsxs)(t.Fragment,{children:["/"!==s.asPath&&(0,t.jsx)(o,{}),(0,t.jsx)("main",{className:"bg-gray-50 max-w-[70em] w-full min-h-[500px] mx-auto relative",children:a})]})};var d=c},4522:function(e,a,s){"use strict";s.r(a),s.d(a,{default:function(){return o}});var t=s(5893),i=s(4779),n=s(6937),r=s(5675),l=s.n(r);function o(){return(0,t.jsxs)(i.Z,{children:[(0,t.jsx)(n.Z,{title:"Tutorials"}),(0,t.jsxs)("div",{className:"px-5 md:px-8 lg:px-10",children:[(0,t.jsx)("h2",{className:"mt-10 md:mt-14 uppercase text-3xl font-bold text-orange-600 tracking-wide mb-8",children:"Tutorials"}),(0,t.jsxs)("article",{className:"pb-10",children:[(0,t.jsx)("h3",{className:"font-bold text-2xl text-gray-700 mb-6",children:"Detect Label Errors in Datasets"}),(0,t.jsx)("h3",{className:"font-bold text-xl text-gray-600 mb-4",children:"▶\xa0\xa0Abstract"}),(0,t.jsx)("p",{className:"px-0 md:px-7",children:"With the rise of large AI models, data assets have gained increasing importance. Understanding how to identify and correct label errors in our datasets is crucial. This is primarily because label errors are pervasive in the era of big data, and rectifying them can significantly enhance our knowledge. Moreover, large AI models are susceptible to overfitting label errors, which hinders their ability to generalize effectively unless label noise is adequately addressed. In this tutorial, we will present typical approaches to handle label noise, such as extracting confident/non-confident examples (indicating likely correct/incorrect labels) using deep network properties and intuitions. Additionally, we will explore methods that focus on directly modelling the label noise, providing theoretical guarantees. By illustrating the intuitions behind state-of-the-art techniques, this tutorial aims to equip researchers and practitioners with valuable insights into effectively managing label noise in datasets."}),(0,t.jsx)("h3",{className:"mt-7 font-bold text-xl text-gray-600 mb-5",children:"▶\xa0\xa0Speaker"}),(0,t.jsxs)("div",{className:"flex w-[20em] sm:w-[25em] px-0 md:px-7",children:[(0,t.jsx)("a",{className:"border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200",href:"https://tongliang-liu.github.io/",target:"_blank",rel:"noreferrer",children:(0,t.jsx)(l(),{src:"/images/committee/tongliang-liu.jpg",width:60,height:60,alt:""})}),(0,t.jsxs)("div",{className:"flex flex-col justify-center",children:[(0,t.jsx)("span",{className:"text-gray-800 font-bold text-lg",children:"Tongliang Liu"}),(0,t.jsx)("span",{className:"text-gray-600 text-sm",children:"University of Sydney"})]})]}),(0,t.jsx)("p",{className:"mt-4 px-0 md:px-7",children:"Tongliang Liu is the Director of Sydney AI Centre at the University of Sydney. He is broadly interested in the fields of trustworthy machine learning and its interdisciplinary applications, with a particular emphasis on learning with noisy labels, adversarial learning, transfer learning, unsupervised learning, and statistical deep learning theory. He has authored and co-authored more than 200 research articles including ICML, NeurIPS, ICLR, CVPR, AAAI, IJCAI, JMLR, and TPAMI. His monograph on machine learning with noisy labels will be published by MIT Press. He is/was a (senior-) meta reviewer for many conferences, such as ICML, NeurIPS, ICLR, UAI, AAAI, IJCAI, and KDD, and was a notable AC for ICLR. He is an Associate Editor of TMLR and is on the Editorial Boards of JMLR and MLJ. He is a recipient of the AI’s 10 to Watch Award from IEEE in 2023, the Future Fellowship Award from Australian Research Council (ARC) in 2022, and the Discovery Early Career Researcher Award (DECRA) from ARC in 2018."})]})]})]})}}},function(e){e.O(0,[856,628,774,888,179],function(){return e(e.s=9160)}),_N_E=e.O()}]);